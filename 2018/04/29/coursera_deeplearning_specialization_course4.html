<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta name="author" content="ysk24ok">
  
  <meta name="description" content="Coursera Deep Learning Specializationのcourse4受講メモ">
  <meta property="og:description" content="Coursera Deep Learning Specializationのcourse4受講メモ">
  
  <meta property="og:image" content="https://ysk24ok.github.io/assets/images/profile.jpeg">
  <meta property="og:title" content="Coursera Deep Learning Specialization course4受講メモ">
  <meta property="og:url" content="https://ysk24ok.github.io/2018/04/29/coursera_deeplearning_specialization_course4.html">
  <meta property="og:type" content="article">
  <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
  <!-- MathJax -->
  <!-- http://docs.mathjax.org/en/latest/start.html#secure-access-to-the-cdn -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ['\\(','\\)'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- bootstrap -->
  <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap.min.css">
  <script src="/assets/js/jquery-2.1.4.min.js"></script>
  <script src="/assets/js/bootstrap.min.js"></script>
  <!-- github.io default -->
  <link rel="stylesheet" type="text/css" href="/assets/css/stylesheet.css" media="screen">
  <link rel="stylesheet" type="text/css" href="/assets/css/github-dark.css" media="screen">
  <link rel="stylesheet" type="text/css" href="/assets/css/print.css" media="print">
  <!-- syntax highlight css -->
  <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" media="screen">
  <!-- My customized css -->
  <link rel="stylesheet" type="text/css" href="/assets/css/linkpreview.css" media="screen">
  <link rel="stylesheet" type="text/css" href="/assets/css/main.css" media="screen">
  <!-- RSS -->
  <link href="/feed.xml" type="application/rss+xml" rel="alternate" title="ysk24ok.github.io" />

  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131519041-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-131519041-1');
  </script>

  <!--[if lt IE 9]>
  <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <title>Coursera Deep Learning Specialization course4受講メモ - ysk24ok.github.io</title>
</head>

  <body>
    <div id="container">
      <div class="inner">
        <header>
  <h1><a href="/">ysk24ok.github.io</a></h1>
</header>
<nav class="navbar navbar-default" role="navigation">
  <ul id="main-navigation" class="nav navbar-nav">
    <li><a href="/">Home</a></li>
    <li><a href="/about">About</a></li>
  </ul>
</nav>

        <div class="post-item">
          <div class="post-header">
  <h1>
    <a href="/2018/04/29/coursera_deeplearning_specialization_course4.html">Coursera Deep Learning Specialization course4受講メモ</a>
  </h1>
  <ul class="post-tags">
    
      <li><a href="#">Coursera</a></li>
    
      <li><a href="#">deep learning</a></li>
    
      <li><a href="#">Japanese</a></li>
    
  </ul>
  
  <div class="post-date">posted on 29 Apr 2018</div>
  
  <hr>
</div>

          <div class="post-content">
            <ul class="social-buttons">
  <!-- hatena bookmark -->
  <li>
    <a href="http://b.hatena.ne.jp/entry/ysk24ok.github.io/2018/04/29/coursera_deeplearning_specialization_course4.html" class="hatena-bookmark-button" data-hatena-bookmark-title="Coursera Deep Learning Specialization course4受講メモ - ysk24ok.github.io" data-hatena-bookmark-layout="simple-balloon" title="このエントリーをはてなブックマークに追加">
      <img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" />
    </a>
    <script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  </li>
  <!-- twitter -->
  <li>
    <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </li>
</ul>

            <p><a href="https://www.coursera.org/specializations/deep-learning">Coursera Deep Learning Specializaton</a>の<a href="https://www.coursera.org/learn/convolutional-neural-networks">course4: Convolutional Neural Networks</a>を修了したのでメモを残しておく。</p>

<!-- more -->

<h1 id="week1">Week1</h1>

<h2 id="convolutional-neural-network">Convolutional Neural Network</h2>

<ul>
  <li>convolutional layer
    <ul>
      <li>畳み込みによってedge detectionなどができる</li>
      <li>padding
        <ul>
          <li>valid: paddingしない</li>
          <li>same: inputとoutputのサイズが同じになるようにpaddingする</li>
        </ul>
      </li>
      <li>stride: filterの移動幅</li>
      <li>入力が縦x横xチャネルの3次元だった場合、filterも3次元に、出力は2次元になる</li>
    </ul>
  </li>
  <li>pooling layer
    <ul>
      <li>max pooling, average pooling</li>
      <li>convolutional layerと異なり、入力が3次元のとき出力も3次元のままになる</li>
    </ul>
  </li>
  <li>Why convolutions?
    <ul>
      <li>parameter sharing
        <ul>
          <li>ある特徴で学習したこと(edge detectionなど)を他の特徴に活かせる</li>
        </ul>
      </li>
      <li>sparsity of connections
        <ul>
          <li>出力のunitは入力のごく一部のunitとしかつながっておらず、<br />
パラメータ数を削減できる</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="week2">Week2</h1>

<h2 id="case-studies">Case studies</h2>

<ul>
  <li>classic networks
    <ul>
      <li>Lenet-5, AlexNet, VGG-16, etc</li>
    </ul>
  </li>
  <li>ResNet
    <ul>
      <li>ある層の出力を、先にある層の(activation関数に通す前の)出力に加える (skip connection)
        <ul>
          <li>$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$</li>
        </ul>
      </li>
      <li>plainなネットワークでは層数を増やすとtraining errorが悪化するが、<br />
residual blockを使うと層数を増やしてもtraining errorは悪化しない</li>
      <li>residual blockが何も学習しなかった場合は重みは0になり、<br />
identity functionに等しくなるので、学習が容易(?)</li>
      <li>residual blockの入力と出力の次元は同じなのでsame convolutionである</li>
    </ul>
  </li>
  <li>Inception network (GoogLeNet)
    <ul>
      <li>1x1, 3x3, 5x5のfilter、poolingによるconvolution結果をchannel方向にstackさせる</li>
      <li>3x3、5x5 filterによるconvolutionは、まず1x1 filterによって次元数を減らしてからおこなう</li>
    </ul>
  </li>
</ul>

<h2 id="practical-advices-for-using-convnets">Practical advices for using ConvNets</h2>

<ul>
  <li>transfer learning
    <ul>
      <li>出力層だけ入れ替える</li>
      <li>最初の層の重みは固定し、後ろの層を学習する</li>
      <li>単に初期化のためだけに使い、全層で学習をおこなう</li>
    </ul>
  </li>
  <li>data augmentation
    <ul>
      <li>mirroring (上下or左右を反転する)</li>
      <li>random cropping (元画像の一部を切り出す)</li>
      <li>color shifting (色を変える)</li>
      <li>画像をディスクから読み出す-&gt;上のような加工を施す-&gt;NNに入力する</li>
    </ul>
  </li>
</ul>

<h1 id="week3">Week3</h1>

<h2 id="detection-algorithms">Detection algorithms</h2>

<ul>
  <li>classificationでは画像の中に含まれるobjectがどのラベルにあたるかを知るだけでよかったが、
object detectionではそれに加えてlocalizationが必要になる
    <ul>
      <li>localizationとは、画像のどの位置にobjectがあるかを特定すること</li>
      <li>例えばNNの出力層にbounding boxの位置に関するユニットを加える
        <ul>
          <li>bounding boxの中心の座標、幅、高さなど</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>より一般的なケースでは、landmarkの座標をNNに出力させる
    <ul>
      <li>face recognitionでは、目や口の両端など</li>
    </ul>
  </li>
  <li>sliding window detection
    <ul>
      <li>画像を入力してそこにobjectが写っているか否かを識別するConvNetを作れば、<br />
1つの大きな画像から小さな画像を切り出す-&gt;forwardprop-&gt;windowを移動させて別の小さな画像を切り出す<br />
ということを繰り返していく</li>
      <li>しかしsliding window detectionはforwardpropの回数が増えるため計算量も増える</li>
      <li>ConvNetの実装を工夫すれば一度のforwardpropで全windowを識別できる</li>
    </ul>
  </li>
  <li>YOLO
    <ul>
      <li>画像を複数のcellに区切る</li>
      <li>objectが複数のcellにまたがっている場合でも、objectの中心が位置するcellがラベルを1にするcellになる</li>
      <li>1つ目のvideoで見たように、classificationとlocalizationを1つのConvNetで学習する</li>
      <li>Convolutional implementationにより複数のcellの学習を1NNでおこなうことができる</li>
    </ul>
  </li>
  <li>IoU (Intersection over Union)
    <ul>
      <li>bouding boxの評価指標</li>
      <li>正しいboxと予測したboxがオーバーラップしている割合</li>
    </ul>
  </li>
  <li>Non-max Suppression
    <ol>
      <li>objectが含まれる確率が閾値以下のcellを除外する</li>
      <li>残ったcellの中で最もobjectが含まれる確率の高いcellを出力とする</li>
      <li>上のステップで出力としたセルとのIoUが0.5以上の
        <ul>
          <li>2と3のステップを繰り返す？
            <ul>
              <li>3のステップ後に残るのは、2で出力としたcellと、そのcellほど確率は高くないがオーバーラップしていないcell？</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
  <li>anchor boxes
    <ul>
      <li>ここまでで紹介した方法では1つのセルに複数objectが含まれていても識別できない</li>
      <li>歩行者用、車用など、あらかじめanchor boxをクラスごとに用意しておき、<br />
IoUの最も高いboxにアサインする
        <ul>
          <li>つまり複数オブジェクトは属するcellは同じだが、属するboxが異なる</li>
        </ul>
      </li>
      <li>出力層のユニットもanchor box数分用意する</li>
    </ul>
  </li>
  <li>R-CNN
    <ul>
      <li>objectが写っている領域の候補をCNNに入力することで画像をセグメント化することができる？</li>
    </ul>
  </li>
</ul>

<h1 id="week4">Week4</h1>

<h2 id="face-recognition">Face Recognition</h2>

<ul>
  <li>face verification vs. face recognition
    <ul>
      <li>前者は、ある人の画像と名前orIDを入力してその画像がその名前の人と一致するかを判定する
        <ul>
          <li>1:1</li>
        </ul>
      </li>
      <li>後者は、ある人の画像を入力するとデータベースを検索して一致する人を取り出す
        <ul>
          <li>1:K</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>One Shot Learning
    <ul>
      <li>1人につき1枚の画像しかない状態でtrainingしてもNNはうまく動かない</li>
      <li>画像の類似度を計算するような関数を考え、verificationをおこなう</li>
    </ul>
  </li>
  <li>Siamese Network
    <ul>
      <li>画像$x_{i}$を入力してforwardpropさせると出力層で128次元のベクトル$f(x_{i})が得られ、<br />
$||f(x_{i})-f(x_{j})||$で類似度を計算できるようにNNを学習する</li>
      <li>loss関数にはtriplet lossを用いる</li>
      <li>アンカー画像とポジティブ画像とネガティブ画像を用意する必要があるため、  <br />
訓練データには同じ人の画像が複数枚存在する必要がある</li>
    </ul>
  </li>
  <li>Triplet lossを用いる以外には、2枚の画像をベクトル化してelement-wiseに類似度を計算したものを特徴量として
ロジスティック回帰に入力し、同じ人か否かを二値分類する手法もある</li>
</ul>

<h2 id="neural-style-transfer">Neural Style Transfer</h2>

<ul>
  <li>cost functionはcontent cost functionとstyle cost functionの線形結合で表す
    <ul>
      <li>content cost functionはVGGなどの既存の事前学習済のnetworkを使い、
浅すぎず深すぎない位置にある層のactivation値が、元画像と生成画像で似ているかどうかで表す</li>
      <li>style cost functionは、スタイル画像と生成画像の異なるchannel間のactivation値が似ているかどうかで表す</li>
    </ul>
  </li>
  <li></li>
</ul>


            <ul class="social-buttons">
  <!-- hatena bookmark -->
  <li>
    <a href="http://b.hatena.ne.jp/entry/ysk24ok.github.io/2018/04/29/coursera_deeplearning_specialization_course4.html" class="hatena-bookmark-button" data-hatena-bookmark-title="Coursera Deep Learning Specialization course4受講メモ - ysk24ok.github.io" data-hatena-bookmark-layout="simple-balloon" title="このエントリーをはてなブックマークに追加">
      <img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" />
    </a>
    <script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  </li>
  <!-- twitter -->
  <li>
    <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </li>
</ul>

          </div>
        </div>
        <footer>
  This page was generated by <a href="https://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
</footer>

      </div>
    </div>
  </body>
</html>
